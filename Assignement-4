##Question 1
%%writefile sum_cuda.cu
#include <stdio.h>
#include <cuda_runtime.h>

#define N 1024

__global__ void computeSums(int *input, int *output) {
    int tid = threadIdx.x;

    if (tid == 0) {
        int sum = 0;
        for (int i = 0; i < N; i++) {
            sum += input[i];
        }
        output[0] = sum;
    } else if (tid == 1) {
        int n = N;
        output[1] = n * (n + 1) / 2;
    }
}

int main() {
    int h_input[N], h_output[2] = {0, 0};
    int *d_input, *d_output;

    // Fill input array from 1 to N
    for (int i = 0; i < N; i++) {
        h_input[i] = i + 1;
    }

    cudaMalloc(&d_input, N * sizeof(int));
    cudaMalloc(&d_output, 2 * sizeof(int));

    cudaMemcpy(d_input, h_input, N * sizeof(int), cudaMemcpyHostToDevice);

    computeSums<<<1, 2>>>(d_input, d_output);
    cudaDeviceSynchronize();

    cudaMemcpy(h_output, d_output, 2 * sizeof(int), cudaMemcpyDeviceToHost);

    printf("Sum using iterative approach (Thread 0): %d\n", h_output[0]);
    printf("Sum using formula (Thread 1):           %d\n", h_output[1]);

    cudaFree(d_input);
    cudaFree(d_output);

    return 0;
}




##Question 2
a)
%%writefile mergesort_compare.cu
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <omp.h>
#include <cuda.h>

#define N 1000

void merge(int* arr, int l, int m, int r) {
    int i, j, k;
    int n1 = m - l + 1;
    int n2 = r - m;

    int *L = (int*)malloc(n1 * sizeof(int));
    int *R = (int*)malloc(n2 * sizeof(int));

    for (i = 0; i < n1; i++) L[i] = arr[l + i];
    for (j = 0; j < n2; j++) R[j] = arr[m + 1 + j];

    i = 0; j = 0; k = l;
    while (i < n1 && j < n2) arr[k++] = (L[i] <= R[j]) ? L[i++] : R[j++];
    while (i < n1) arr[k++] = L[i++];
    while (j < n2) arr[k++] = R[j++];

    free(L);
    free(R);
}

void mergeSortPipeline(int* arr, int l, int r) {
    if (l < r) {
        int m = (l + r) / 2;
        #pragma omp parallel sections
        {
            #pragma omp section
            mergeSortPipeline(arr, l, m);
            #pragma omp section
            mergeSortPipeline(arr, m + 1, r);
        }
        merge(arr, l, m, r);
    }
}

__device__ void mergeCuda(int* arr, int* temp, int l, int m, int r) {
    int i = l, j = m + 1, k = l;
    while (i <= m && j <= r) temp[k++] = (arr[i] <= arr[j]) ? arr[i++] : arr[j++];
    while (i <= m) temp[k++] = arr[i++];
    while (j <= r) temp[k++] = arr[j++];
    for (int x = l; x <= r; x++) arr[x] = temp[x];
}

__global__ void mergeSortCuda(int* arr, int* temp, int width, int n) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int l = tid * (2 * width);
    int m = l + width - 1;
    int r = l + 2 * width - 1;
    if (r >= n) r = n - 1;
    if (m < r)
        mergeCuda(arr, temp, l, m, r);
}

void parallelMergeSortCuda(int* arr, int n) {
    int *d_arr, *d_temp;
    cudaMalloc(&d_arr, n * sizeof(int));
    cudaMalloc(&d_temp, n * sizeof(int));
    cudaMemcpy(d_arr, arr, n * sizeof(int), cudaMemcpyHostToDevice);

    for (int width = 1; width < n; width *= 2) {
        int numThreads = (n + (2 * width) - 1) / (2 * width);
        mergeSortCuda<<<(numThreads + 255) / 256, 256>>>(d_arr, d_temp, width, n);
        cudaDeviceSynchronize();
    }

    cudaMemcpy(arr, d_arr, n * sizeof(int), cudaMemcpyDeviceToHost);
    cudaFree(d_arr);
    cudaFree(d_temp);
}

void printArray(int* arr, int n) {
    for (int i = 0; i < n; i++) {
        printf("%d ", arr[i]);
        if ((i + 1) % 20 == 0) printf("\n");
    }
    printf("\n");
}

int main() {
    int* arr = (int*)malloc(N * sizeof(int));
    int* arr_copy = (int*)malloc(N * sizeof(int));
    srand(time(NULL));
    for (int i = 0; i < N; i++) {
        arr[i] = rand() % 10000;
        arr_copy[i] = arr[i];
    }

    printf("Unsorted Array:\n");
    printArray(arr, N);

    double start = omp_get_wtime();
    mergeSortPipeline(arr, 0, N - 1);
    double end = omp_get_wtime();
    printf("\nSorted Array using Pipelined Merge Sort:\n");
    printArray(arr, N);
    printf("\nPipelined Merge Sort Time: %.6f seconds\n", end - start);

    start = omp_get_wtime();
    parallelMergeSortCuda(arr_copy, N);
    end = omp_get_wtime();
    printf("\nSorted Array using CUDA Merge Sort:\n");
    printArray(arr_copy, N);
    printf("\nCUDA Merge Sort Time: %.6f seconds\n", end - start);

    free(arr);
    free(arr_copy);
    return 0;
}


b)
%%writefile mergesort_compare.cu
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <omp.h>
#include <cuda.h>

int N;

void merge(int* arr, int l, int m, int r) {
    int i, j, k;
    int n1 = m - l + 1;
    int n2 = r - m;

    int *L = (int*)malloc(n1 * sizeof(int));
    int *R = (int*)malloc(n2 * sizeof(int));

    for (i = 0; i < n1; i++) L[i] = arr[l + i];
    for (j = 0; j < n2; j++) R[j] = arr[m + 1 + j];

    i = 0; j = 0; k = l;
    while (i < n1 && j < n2) arr[k++] = (L[i] <= R[j]) ? L[i++] : R[j++];
    while (i < n1) arr[k++] = L[i++];
    while (j < n2) arr[k++] = R[j++];

    free(L);
    free(R);
}

void mergeSortPipeline(int* arr, int l, int r) {
    if (l < r) {
        int m = (l + r) / 2;
        #pragma omp parallel sections
        {
            #pragma omp section
            mergeSortPipeline(arr, l, m);
            #pragma omp section
            mergeSortPipeline(arr, m + 1, r);
        }
        merge(arr, l, m, r);
    }
}

__device__ void mergeCuda(int* arr, int* temp, int l, int m, int r) {
    int i = l, j = m + 1, k = l;
    while (i <= m && j <= r) temp[k++] = (arr[i] <= arr[j]) ? arr[i++] : arr[j++];
    while (i <= m) temp[k++] = arr[i++];
    while (j <= r) temp[k++] = arr[j++];
    for (int x = l; x <= r; x++) arr[x] = temp[x];
}

__global__ void mergeSortCuda(int* arr, int* temp, int width, int n) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int l = tid * (2 * width);
    int m = l + width - 1;
    int r = l + 2 * width - 1;
    if (r >= n) r = n - 1;
    if (m < r)
        mergeCuda(arr, temp, l, m, r);
}

void parallelMergeSortCuda(int* arr, int n) {
    int *d_arr, *d_temp;
    cudaMalloc(&d_arr, n * sizeof(int));
    cudaMalloc(&d_temp, n * sizeof(int));
    cudaMemcpy(d_arr, arr, n * sizeof(int), cudaMemcpyHostToDevice);

    for (int width = 1; width < n; width *= 2) {
        int numThreads = (n + (2 * width) - 1) / (2 * width);
        mergeSortCuda<<<(numThreads + 255) / 256, 256>>>(d_arr, d_temp, width, n);
        cudaDeviceSynchronize();
    }

    cudaMemcpy(arr, d_arr, n * sizeof(int), cudaMemcpyDeviceToHost);
    cudaFree(d_arr);
    cudaFree(d_temp);
}

void printArray(int* arr, int n) {
    for (int i = 0; i < n; i++) {
        printf("%d ", arr[i]);
        if ((i + 1) % 20 == 0) printf("\n");
    }
    printf("\n");
}

int main(int argc, char** argv) {
    if (argc != 2) {
    printf("Usage: %s <array_size>\n", argv[0]);
    return 1;
    }
    N = atoi(argv[1]);

    int* arr = (int*)malloc(N * sizeof(int));
    int* arr_copy = (int*)malloc(N * sizeof(int));
    srand(time(NULL));
    for (int i = 0; i < N; i++) {
        arr[i] = rand() % 10000;
        arr_copy[i] = arr[i];
    }

    printf("Unsorted Array:\n");
    printArray(arr, N);

    double start = omp_get_wtime();
    mergeSortPipeline(arr, 0, N - 1);
    double end = omp_get_wtime();
    printf("\nSorted Array using Pipelined Merge Sort:\n");
    printArray(arr, N);
    printf("\nPipelined Merge Sort Time: %.6f seconds\n", end - start);

    start = omp_get_wtime();
    parallelMergeSortCuda(arr_copy, N);
    end = omp_get_wtime();
    printf("\nSorted Array using CUDA Merge Sort:\n");
    printArray(arr_copy, N);
    printf("\nCUDA Merge Sort Time: %.6f seconds\n", end - start);

    free(arr);
    free(arr_copy);
    return 0;
}


c)
import subprocess
import matplotlib.pyplot as plt

sizes = [1000, 5000, 10000, 50000, 100000]
cpu_times = []
gpu_times = []

# Compile the CUDA code
!nvcc -Xcompiler -fopenmp mergesort_compare.cu -o mergesort_compare

for size in sizes:
    result = subprocess.run(
        ['./mergesort_compare', str(size)],
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
        text=True
    )
    output = result.stdout

    # Extract timing data
    cpu_line = [line for line in output.splitlines() if "Pipelined Merge Sort Time" in line]
    gpu_line = [line for line in output.splitlines() if "CUDA Merge Sort Time" in line]

    cpu_time = float(cpu_line[0].split()[-2])
    gpu_time = float(gpu_line[0].split()[-2])

    cpu_times.append(cpu_time)
    gpu_times.append(gpu_time)

# Plotting
plt.figure(figsize=(10, 6))
plt.plot(sizes, cpu_times, label='Pipelined Merge Sort (CPU)', marker='o')
plt.plot(sizes, gpu_times, label='CUDA Merge Sort (GPU)', marker='s')
plt.xlabel('Array Size (N)')
plt.ylabel('Execution Time (seconds)')
plt.title('Performance Comparison: CPU vs CUDA Merge Sort')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()
